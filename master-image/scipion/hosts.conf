[localhost]
PARALLEL_COMMAND = mpirun -np %_(JOB_NODES)d %_(COMMAND)s
NAME = KUBERNETES
MANDATORY = 1
SUBMIT_COMMAND = bash %_(JOB_SCRIPT)s
SUBMIT_TEMPLATE = #!/bin/bash
    echo $$

    ### Set environment variable to know running mode is non interactive
    #export XMIPP_IN_QUEUE=1
    # This option is probably not required due to working X11 forwarding
    export XMIPP_IN_QUEUE=0

    # TODO tmp workaround - problem with missing absolute path to the project
    job_script="%_(JOB_SCRIPT)s"
    job_workdir=$(echo $job_script | sed 's/\(\/mnt\/vol-project\/[^/]*\/\).*/\1/')

    job_command="%_(JOB_COMMAND)s"

    job_script_binary=$(echo "$job_command" | awk '{$1=$1};1' | cut -d' ' -f1)
    if [ -z "$job_script_binary" ]; then
        exit 11
    fi

    # TODO tmp workaround - dictionary with binaries and tools
    job_tool=$(cat "/opt/scipion/tool-dictionary.csv" | grep "^${job_script_binary}" | cut -d';' -f2 | head -n 1)
    if [ -z "$job_tool" ]; then
        exit 12
    fi

    K8S_JOB_ID=$(helm template \
        --set instance.namespace=$(cat /var/run/secrets/kubernetes.io/serviceaccount/namespace) \
        --set instance.name="$INSTANCE_NAME" \
        --set instance.prefix="$INSTANCE_PREFIX" \
        --set instance.releaseChannel="$RELEASE_CHANNEL" \
        --set instance.submitpid="$$" \
        --set job.name="%_(JOB_NAME)s" \
        --set job.tool="$job_tool" \
        --set job.command="$job_command" \
        --set job.workdir="$job_workdir" \
        --set job.xmippInQueue="$XMIPP_IN_QUEUE" \
        --set job.gpu.allow="%_(JOB_GPU_ALLOW)s" \
        --set job.gpu.dedicated="%_(JOB_GPU_DEDICATED)s" \
        --set job.gpu.sharedMem="%_(JOB_GPU_SHARED_MEM)s" \
        --set od.dataset.spaceIdShort="$OD_DATASET_SPACEIDSHORT" \
        --set od.project.spaceIdShort="$OD_PROJECT_SPACEIDSHORT" \
        --set instance.mincpu="%_(JOB_THREADS)d" \
        --set instance.maxcpu="%_(JOB_THREADS)d" \
        --set instance.minram="%_(JOB_MEMORY)sGi" \
        --set instance.maxram="%_(JOB_MEMORY)sGi" \
        /opt/kubernetes/tool/ | kubectl apply -f - | cut -d' ' -f1)

    nohup /opt/scipion/job-watchdog.sh </dev/null &>/dev/null "$K8S_JOB_ID" &

    echo $$

CANCEL_COMMAND = #!/bin/bash
    export job_id="%_(JOB_ID)s"
    # scipion's var JOB_NAME does not work in the cancel cmd
    export job_name=`kubectl get job | grep "${INSTANCE_PREFIX}-${INSTANCE_NAME}-tool" | grep "$job_id" | cut -d"-" -f5`

    kubectl delete job "${INSTANCE_PREFIX}-${INSTANCE_NAME}-tool-$job_name-$job_id"

CHECK_COMMAND =  #!/bin/bash
    j_dir="/mnt/shared/jobs/"
    mkdir -p "$j_dir"
    j_file=$(ls "$j_dir" | grep "$INSTANCE_NAME" | grep "%_(JOB_ID)s")

    if [ -z "$j_file" ]; then
        echo -n "error"
    fi

    j_path="${j_dir}/${j_file}"

    if [ -f "$j_path" ] && [ "$(cat $j_path)" = "done" ]; then
        echo -n ""
        exit 0
    else
        echo -n "error"
    fi

QUEUES = {
    "kubernetes-queue": [
        ["JOB_MEMORY", "4", "Memory (GiB)", "Select amount of memory (in gibibytes) for this job."],
        ["JOB_GPU_ALLOW", "false", "Allow GPU", "Make GPU available for this protocol. This option does not force the Scipion's plugin to use a GPU."],
        ["JOB_GPU_DEDICATED", "false", "Dedicated GPU (if GPU allowed)", "Select Dedicated (true) or Shared (false) GPU. Shared GPU will be shared with other users in the cluster. This option is relevant only for GPU-accelerated protocol."],
        ["JOB_GPU_SHARED_MEM", "2", "GPU memory (GiB) (Shared GPU only)", "Select amount of GPU memory (in gibibytes) for this job. This value is relevant only if you choose shared GPU in the previous option."],
        ["QUEUE_FOR_JOBS", "Y", "queue-for-jobs (always set to 'Y')", "Allows to submit smaller jobs to the Kubernetes queue system."]
    ] }
